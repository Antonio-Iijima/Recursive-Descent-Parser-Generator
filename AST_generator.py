from utils import *



def process_syntax(syntax: list[str]) -> dict:
    return {                                                                          # "ε"          
        rule.strip() : [[s for s in split_nonterminals(alternative.strip()) if not s in ("",)] for alternative in pattern.split("|")]
        for rule, pattern in (line.split("::=") for line in syntax)
    }


def process_semantics(semantics: str) -> str:
    """Current implementation does nothing."""
    return semantics


def show_grammar(grammar: dict) -> None:
    offset = max(len(p) for p in grammar)

    for p, r in grammar.items(): 
        print(f"{p}{" " * (offset - len(p))} ::= {" | ".join("".join(s) for s in r)}")
    
    print()

    return offset


def generate_AST(syntax: list[str], semantics, debug: bool = False) -> set:
    """Generates an AST from an EBNF grammar (BNF with `|` for convenience) for context-free languages."""

    print("Compiling grammar...")

    print()

    GRAMMAR = process_syntax(syntax)
    offset = show_grammar(GRAMMAR)

    TERMINALS = set(
        token
                for alternatives in GRAMMAR.values()
            for pattern in alternatives
        for token in pattern if is_terminal(token)
        )

    AST_text = f"""'''!!! THIS FILE IS AUTOMATICALLY GENERATED - PLEASE DO NOT MODIFY !!!'''      



from parser import Rule



##### ABSTRACT SYNTAX TREE #####


"""
#     if "ε" in TERMINALS: AST_text += """
# class Epsilon(Rule):
#     '''Rule: `_ ::= ε`'''
#     name: str = "ε"
# """

    for (rule, alternatives) in GRAMMAR.items():

        docstring = f"{rule} ::= {" | ".join("".join(pattern) for pattern in alternatives)}"
        AST_text += f"""
class {embed_nonterminal(rule)}(Rule):
    '''Rule: `{docstring}`'''
    name: str = "{rule}"
"""

    AST_text += f"""

        
##### GRAMMAR #####


    
GRAMMAR = {{
    {",\n    ".join(f'''{embed_nonterminal(rule)}{" " * (offset - len(rule))} : [{
        ",".join(f"[{", ".join(embed_nonterminal(s) if is_nonterminal(s) else f"'{s}'" for s in alternative)}]"
                for alternative in alternatives)}]'''
                    for rule, alternatives in GRAMMAR.items())}
}}


K = {max(map(len, (pattern for alternatives in GRAMMAR.values() for pattern in alternatives)))}
EPSILON = "ε"

TERMINALS = {TERMINALS}.difference({{EPSILON}})


TOKENS = TERMINALS.union(GRAMMAR.keys())


OPERATORS = {{{", ".join(embed_nonterminal(t) if is_nonterminal(t) else f"'{t}'" for t in set(
        token 
                for alternatives in GRAMMAR.values()
            for pattern in alternatives
        for token in pattern if (
            len(pattern) > 1
            and is_terminal(token)
            and (not token == pattern[-1])
            and any(is_nonterminal(x) for x in pattern)
        )))}}}


EXPECTED_TOKENS = {{ token : [] for token in TOKENS }}


def expand_expected(token, x):
    EXPECTED_TOKENS[token].append(x)

    for alternative in GRAMMAR.get(x, []):
        if len(alternative) > 0:
            y = alternative[0]
            if not y in EXPECTED_TOKENS[token] and not y in TERMINALS.difference(OPERATORS):
                expand_expected(token, y)

for alternatives in GRAMMAR.values():
    for pattern in alternatives:
        for i, token in enumerate(pattern[:-1]):
            expand_expected(token, pattern[i+1])

def retype(x): return type(x) if isinstance(x, Rule) else x

def is_expected(e, x: Rule|str) -> list: 
    expected = EXPECTED_TOKENS.get(retype(x), [])
    return retype(e) in expected
"""


    with open("AST.py", "w") as file:
        file.write(AST_text)

    print()
    with open("eval.py", "w") as file:
        print("Generating eval...")
        file.write(generate_eval(GRAMMAR, semantics))
        
    print("\nDone!")
 


def generate_eval(grammar: dict, semantics: str) -> str:
    # AST-bound operations should be prefixed with 'p_'; 
    # global functions and variables (e.g. the environment) with 'g_'

    eval_text = f"""'''!!! THIS FILE IS AUTOMATICALLY GENERATED - PLEASE DO NOT MODIFY !!!'''      
    
    

from importlib.machinery import SourceFileLoader
s = SourceFileLoader("semantics", "{semantics}").load_module()



##### EVAL #####



def evaluate(AST):
    from AST import Rule

    if isinstance(AST, Rule):
        expr = list(map(evaluate, AST.children))

        match type(AST).__name__:
"""
        
    for rule in grammar.keys():

        eval_text += f"""
            case "{embed_nonterminal(rule)}": 
                return s.p_{embed_nonterminal(rule).lower()}(expr)
"""

    eval_text += """
    return "" if AST == None else AST
"""

    return eval_text
