from utils import *



def process_syntax(syntax: list[str]) -> dict:
    return {
        rule.strip() : [[s for s in split_nonterminals(alternative.strip()) if not s == ""] for alternative in pattern.split("|")]
        for rule, pattern in (line.split("::=") for line in syntax)
    }


def process_semantics(semantics: str) -> str:
    """Current implementation does nothing."""
    return semantics


def show_grammar(grammar: dict) -> None:
    offset = max(len(p) for p in grammar)

    for p, r in grammar.items(): 
        print(f"{p}{" " * (offset - len(p))} ::= {" | ".join("".join(s) for s in r)}")
    
    print()

    return offset


def generate_AST(syntax: list[str], semantics, debug: bool = False) -> set:
    """Generates an AST from an EBNF grammar (BNF with `|` for convenience) for context-free languages."""

    print("Compiling grammar...")

    print()

    GRAMMAR = process_syntax(syntax)
    offset = show_grammar(GRAMMAR)

    terminals = set(
        token
                    for alternatives in GRAMMAR.values()
                for pattern in alternatives
            for token in pattern
        if is_terminal(token)
        )

    AST_text = f"""'''!!! THIS FILE IS AUTOMATICALLY GENERATED - PLEASE DO NOT MODIFY !!!'''      



from parser import Rule



##### ABSTRACT SYNTAX TREE #####


"""
    
    for (rule, alternatives) in GRAMMAR.items():

        docstring = f"{rule} ::= {" | ".join("".join(pattern) for pattern in alternatives)}"
        AST_text += f"""
class {embed_nonterminal(rule)}(Rule):
    '''Rule: `{docstring}`'''
    name: str = "{rule}"
"""

    AST_text += f"""

        
GRAMMAR = {{
    {",\n    ".join(f'''{embed_nonterminal(rule)}{" " * (offset - len(rule))} : [{
        ",".join(f"[{", ".join(embed_nonterminal(s) if is_nonterminal(s) else f"'{s}'" for s in alternative)}]"
                for alternative in alternatives)}]'''
                    for rule, alternatives in GRAMMAR.items())}
}}
    
TERMINALS = {terminals}
"""


    with open("AST.py", "w") as file:
        file.write(AST_text)

    print()
    with open("eval.py", "w") as file:
        print("Generating eval...")
        file.write(generate_eval(GRAMMAR, semantics))
        
    print("\nDone!")
 


def generate_eval(grammar: dict, semantics: str) -> str:
    # AST-bound operations should be prefixed with 'p_'; 
    # global functions and variables (e.g. the environment) with 'g_'

    eval_text = f"""'''!!! THIS FILE IS AUTOMATICALLY GENERATED - PLEASE DO NOT MODIFY !!!'''      
    
    

from importlib.machinery import SourceFileLoader
s = SourceFileLoader("semantics", "{semantics}").load_module()



##### EVAL #####



def evaluate(AST):
    # if not isinstance(AST, str): print(type(AST).__name__, AST.children)
    match type(AST).__name__:
"""
        
    for rule in grammar.keys():

        eval_text += f"""
        case "{embed_nonterminal(rule)}": 
            return s.p_{embed_nonterminal(rule).lower()}(list(map(evaluate, AST.children)))
"""

    eval_text += """
        case "NoneType":
            return ""

        case _: 
            return AST
"""

    return eval_text
